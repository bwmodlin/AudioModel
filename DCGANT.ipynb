{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 03:16:45.146596: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.3.0 (SDL 2.24.2, Python 3.10.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benmodlin/miniconda3/envs/py4sci/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from utilities import format_batch_dcgan, manage_batch_2c\n",
    "import statistics\n",
    "import pretty_midi as pm\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.Sequential()\n",
    "generator.add(layers.Dense(1250 * 11 * 256, use_bias=False, input_shape=(100,)))\n",
    "generator.add(layers.BatchNormalization())\n",
    "generator.add(layers.LeakyReLU())\n",
    "\n",
    "generator.add(layers.Reshape((1250, 11, 256)))\n",
    "# (2500, 11, 256)\n",
    "\n",
    "generator.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "# (2500, 11, 128)\n",
    "\n",
    "generator.add(layers.BatchNormalization())\n",
    "generator.add(layers.LeakyReLU())\n",
    "\n",
    "generator.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 1), padding='same', use_bias=False))\n",
    "# (5000, 11, 64)\n",
    "\n",
    "generator.add(layers.BatchNormalization())\n",
    "generator.add(layers.LeakyReLU())\n",
    "\n",
    "generator.add(layers.Conv2DTranspose(2, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "# (10000, 22, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = tf.keras.Sequential()\n",
    "discriminator.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                    input_shape=[5000, 22, 2]))\n",
    "discriminator.add(layers.LeakyReLU())\n",
    "discriminator.add(layers.Dropout(0.3))\n",
    "\n",
    "discriminator.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "discriminator.add(layers.LeakyReLU())\n",
    "discriminator.add(layers.Dropout(0.3))\n",
    "\n",
    "discriminator.add(layers.Flatten())\n",
    "discriminator.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    #print(real_output,fake_output)\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dcgan(epochs):\n",
    "    batch_manager = manage_batch_2c('trainfill5.pickle', batch_size)\n",
    "    for i in range(epochs):\n",
    "        batches = batch_manager.new_epoch()\n",
    "        for batch in batches:\n",
    "            formatted_batch = batch\n",
    "            noise = tf.random.normal([batch_size, noise_dim])\n",
    "            \n",
    "            with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                generated_images = generator(noise, training=True)\n",
    "\n",
    "                real_output = discriminator(formatted_batch, training=True)\n",
    "                fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "                gen_loss = generator_loss(fake_output)\n",
    "                disc_loss = discriminator_loss(real_output, fake_output)\n",
    "                print(gen_loss, disc_loss)\n",
    "\n",
    "            gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "            gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "            generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "            discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "        \n",
    "        generator.save(\"./modelsave/gen\" + str(28 + i+1) + \".h5\")\n",
    "        discriminator.save(\"./modelsave/dis\" + str(28 + i+1) + \".h5\")\n",
    "        print(\"finished epoch!\", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.5077245, shape=(), dtype=float32) tf.Tensor(0.5798072, shape=(), dtype=float32)\n",
      "tf.Tensor(3.982379e-06, shape=(), dtype=float32) tf.Tensor(12.895141, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4113873, shape=(), dtype=float32) tf.Tensor(1.3738706, shape=(), dtype=float32)\n",
      "tf.Tensor(12.919416, shape=(), dtype=float32) tf.Tensor(3.9590256, shape=(), dtype=float32)\n",
      "tf.Tensor(15.401765, shape=(), dtype=float32) tf.Tensor(6.796436, shape=(), dtype=float32)\n",
      "tf.Tensor(11.441585, shape=(), dtype=float32) tf.Tensor(4.023897, shape=(), dtype=float32)\n",
      "tf.Tensor(5.3105164, shape=(), dtype=float32) tf.Tensor(1.6013298, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29198056, shape=(), dtype=float32) tf.Tensor(1.6445138, shape=(), dtype=float32)\n",
      "tf.Tensor(0.044939484, shape=(), dtype=float32) tf.Tensor(3.6573448, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15985912, shape=(), dtype=float32) tf.Tensor(2.2879338, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "finished epoch! 0\n",
      "tf.Tensor(1.4612933, shape=(), dtype=float32) tf.Tensor(0.4441322, shape=(), dtype=float32)\n",
      "tf.Tensor(4.5745316, shape=(), dtype=float32) tf.Tensor(0.9183375, shape=(), dtype=float32)\n",
      "tf.Tensor(6.238467, shape=(), dtype=float32) tf.Tensor(1.2176892, shape=(), dtype=float32)\n",
      "tf.Tensor(6.917112, shape=(), dtype=float32) tf.Tensor(1.0210145, shape=(), dtype=float32)\n",
      "tf.Tensor(6.965121, shape=(), dtype=float32) tf.Tensor(1.6465145, shape=(), dtype=float32)\n",
      "tf.Tensor(5.580243, shape=(), dtype=float32) tf.Tensor(0.5315804, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0116143, shape=(), dtype=float32) tf.Tensor(0.6219117, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1189384, shape=(), dtype=float32) tf.Tensor(0.8070061, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8504666, shape=(), dtype=float32) tf.Tensor(0.87960327, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48112002, shape=(), dtype=float32) tf.Tensor(1.1063834, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "finished epoch! 1\n",
      "tf.Tensor(0.8215466, shape=(), dtype=float32) tf.Tensor(0.78281325, shape=(), dtype=float32)\n",
      "tf.Tensor(1.692111, shape=(), dtype=float32) tf.Tensor(0.4199018, shape=(), dtype=float32)\n",
      "tf.Tensor(2.8390114, shape=(), dtype=float32) tf.Tensor(0.44323483, shape=(), dtype=float32)\n",
      "tf.Tensor(3.707066, shape=(), dtype=float32) tf.Tensor(1.1020402, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_dcgan\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[83], line 20\u001b[0m, in \u001b[0;36mtrain_dcgan\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(gen_loss, disc_loss)\n\u001b[1;32m     19\u001b[0m gradients_of_generator \u001b[38;5;241m=\u001b[39m gen_tape\u001b[38;5;241m.\u001b[39mgradient(gen_loss, generator\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[0;32m---> 20\u001b[0m gradients_of_discriminator \u001b[38;5;241m=\u001b[39m \u001b[43mdisc_tape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisc_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m generator_optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients_of_generator, generator\u001b[38;5;241m.\u001b[39mtrainable_variables))\n\u001b[1;32m     23\u001b[0m discriminator_optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients_of_discriminator, discriminator\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "File \u001b[0;32m~/miniconda3/envs/py4sci/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1113\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1107\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1108\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1109\u001b[0m           output_gradients))\n\u001b[1;32m   1110\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1111\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1113\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[1;32m   1122\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/miniconda3/envs/py4sci/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py4sci/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:160\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    158\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m~/miniconda3/envs/py4sci/lib/python3.10/site-packages/tensorflow/python/ops/nn_grad.py:45\u001b[0m, in \u001b[0;36m_Conv2DBackpropInputGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"The derivatives for deconvolution.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m  the gradients w.r.t. the input and the filter\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# functions for performance reasons in Eager mode. See _Conv2DGrad.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m---> 45\u001b[0m     \u001b[43mgen_nn_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d_backprop_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdilations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdilations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrides\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpadding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplicit_paddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexplicit_paddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_cudnn_on_gpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     55\u001b[0m     gen_nn_ops\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m     56\u001b[0m         grad,\n\u001b[1;32m     57\u001b[0m         op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     58\u001b[0m         dilations\u001b[38;5;241m=\u001b[39mop\u001b[38;5;241m.\u001b[39mget_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdilations\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     59\u001b[0m         strides\u001b[38;5;241m=\u001b[39mop\u001b[38;5;241m.\u001b[39mget_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrides\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     60\u001b[0m         padding\u001b[38;5;241m=\u001b[39mop\u001b[38;5;241m.\u001b[39mget_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpadding\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     61\u001b[0m         explicit_paddings\u001b[38;5;241m=\u001b[39mop\u001b[38;5;241m.\u001b[39mget_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplicit_paddings\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     62\u001b[0m         use_cudnn_on_gpu\u001b[38;5;241m=\u001b[39mop\u001b[38;5;241m.\u001b[39mget_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cudnn_on_gpu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     63\u001b[0m         data_format\u001b[38;5;241m=\u001b[39mop\u001b[38;5;241m.\u001b[39mget_attr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_format\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[1;32m     64\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/py4sci/lib/python3.10/site-packages/tensorflow/python/ops/gen_nn_ops.py:1256\u001b[0m, in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   1255\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1256\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConv2DBackpropFilter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_backprop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrides\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_cudnn_on_gpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpadding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexplicit_paddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplicit_paddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdilations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dcgan(25)\n",
    "#generator.save(\"./modelsave/gen\" + \"25final\" + \".h5\")\n",
    "#discriminator.save(\"./modelsave/dis\" + \"25final\" + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-14.8159075]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "noise = tf.random.normal([1, noise_dim])\n",
    "gen_r = generator(noise, training=False)\n",
    "print(discriminator(gen_r, training=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5000, 22, 2)\n"
     ]
    }
   ],
   "source": [
    "print(gen_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tones = [36, 38, 40, 37, 48, 50, 45, 47, 43, 58, 46, 26, 42, 22, 44, 49, 55, 57, 52, 51, 59, 53]\n",
    "tone_map = {}\n",
    "tones.sort()\n",
    "time_resolution = 0.00089\n",
    "\n",
    "for i in range(len(tones)):\n",
    "    tone_map[i] = tones[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0078292815\n",
      "4\n",
      "0.015448219\n",
      "4\n",
      "0.008532749\n",
      "4\n",
      "0.0078736255\n",
      "4\n",
      "0.014251681\n",
      "4\n",
      "0.0032438072\n",
      "4\n",
      "0.015321752\n",
      "4\n",
      "0.033975\n",
      "4\n",
      "0.035480957\n",
      "4\n",
      "0.018557828\n",
      "4\n",
      "0.018739086\n",
      "8\n",
      "0.06137315\n",
      "8\n",
      "0.042631365\n",
      "8\n",
      "0.08586148\n",
      "8\n",
      "0.033520203\n",
      "8\n",
      "0.078552544\n",
      "8\n",
      "0.095992364\n",
      "8\n",
      "0.067473486\n",
      "8\n",
      "0.02378441\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "values = []\n",
    "array = np.array(gen_r)\n",
    "count = 0\n",
    "\n",
    "test_array = np.zeros((5000, 22))\n",
    "for i in range(5000):\n",
    "    for j in range(22):\n",
    "        value = array[0][i][j]\n",
    "        values.append(value[0])\n",
    "        \n",
    "        if value[0] > 0:\n",
    "            print(value[0])\n",
    "            test_array[i][j] = (value[1] * 64) + 64\n",
    "            print(j)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty PrettyMIDI object\n",
    "midi = pm.PrettyMIDI()\n",
    "\n",
    "# create an instrument object for drums\n",
    "drums = pm.Instrument(program=0, is_drum=True)\n",
    "\n",
    "# specify the tempo and time signature for the drum sequence\n",
    "#midi.estimate_tempo()\n",
    "#midi.time_signature_changes.append(pm.TimeSignature(4, 4))\n",
    "tone_runs = [0] * 22\n",
    "for i, row in enumerate(test_array):\n",
    "    for tone, velocity in enumerate(row):\n",
    "        if velocity != 0:\n",
    "            if tone_runs[tone] != 0:\n",
    "                tone_runs[tone][1] = i\n",
    "            else:\n",
    "                tone_runs[tone] = [i, i+1, velocity]\n",
    "        else:\n",
    "            tone_run_data = tone_runs[tone]\n",
    "            if tone_run_data != 0:\n",
    "                drums.notes.append(pm.Note(\n",
    "                    velocity = int(tone_run_data[2]),\n",
    "                    pitch = int(tone_map[tone]),\n",
    "                    start = tone_run_data[0] * time_resolution,\n",
    "                    end = tone_run_data[1] * time_resolution\n",
    "                ))\n",
    "            \n",
    "            tone_runs[tone] = 0\n",
    "            \n",
    "for i, run in enumerate(tone_runs):\n",
    "    if run != 0:\n",
    "        tone_run_data = run\n",
    "        drums.notes.append(pm.Note(\n",
    "                        velocity = int(tone_run_data[2]),\n",
    "                        pitch = int(tone_map[i]),\n",
    "                        start = tone_run_data[0] * time_resolution,\n",
    "                        end = tone_run_data[1] * time_resolution\n",
    "                    ))\n",
    "\n",
    "# add the drums instrument to the MIDI file\n",
    "midi.instruments.append(drums)\n",
    "\n",
    "# write the MIDI file to disk\n",
    "midi.write('drums2.mid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Note(start=0.045390, end=0.046280, pitch=38, velocity=45), Note(start=1.326990, end=1.327880, pitch=38, velocity=46), Note(start=1.330550, end=1.331440, pitch=38, velocity=46), Note(start=1.334110, end=1.335000, pitch=38, velocity=47), Note(start=1.337670, end=1.338560, pitch=38, velocity=47), Note(start=1.341230, end=1.342120, pitch=38, velocity=47), Note(start=1.344790, end=1.345680, pitch=38, velocity=47), Note(start=1.348350, end=1.349240, pitch=38, velocity=50), Note(start=1.351910, end=1.352800, pitch=38, velocity=49), Note(start=1.355470, end=1.356360, pitch=38, velocity=45), Note(start=1.504990, end=1.505880, pitch=44, velocity=50), Note(start=1.508550, end=1.509440, pitch=44, velocity=52), Note(start=1.512110, end=1.513000, pitch=44, velocity=52), Note(start=1.516560, end=1.517450, pitch=44, velocity=49), Note(start=1.520120, end=1.521010, pitch=44, velocity=47), Note(start=1.523680, end=1.524570, pitch=44, velocity=47)]\n"
     ]
    }
   ],
   "source": [
    "print([note for note in drums.notes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
